import requests
from bs4 import BeautifulSoup
import random

def fetch_real_data(city, property_type):
    """
    ğŸ™ï¸ ØªØ¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¹Ù‚Ø§Ø±Ø§Øª Ù…Ù† Ù…ÙˆØ§Ù‚Ø¹ Ù…Ø®ØªÙ„ÙØ© (ØªØ¬Ø±ÙŠØ¨ÙŠØ©)
    """
    urls = [
        f"https://sa.aqar.fm/{city}",
        f"https://www.bayut.sa/{city}",
        f"https://haraj.com.sa/{city}",
        f"https://www.propertyfinder.sa/ar/buy/{city}",
        f"https://www.zillow.com/{city}-real-estate/"
    ]
    
    prices = []
    
    for url in urls:
        try:
            response = requests.get(url, timeout=8)
            if response.status_code == 200:
                soup = BeautifulSoup(response.text, 'lxml')
                text = soup.get_text()
                numbers = [int(n.replace(',', '')) for n in text.split() if n.replace(',', '').isdigit()]
                # ÙÙ„ØªØ±Ø© Ø§Ù„Ø£Ø³Ø¹Ø§Ø± Ø§Ù„ÙˆØ§Ù‚Ø¹ÙŠØ©
                prices += [n for n in numbers if 100000 < n < 10000000]
        except Exception as e:
            print("âš ï¸ ÙØ´Ù„ Ø§Ù„Ø¬Ù„Ø¨ Ù…Ù†:", url, "| Ø§Ù„Ø®Ø·Ø£:", e)

    if len(prices) < 10:
        return None  # Ù†Ø±Ø¬Ø¹ None Ø¥Ø°Ø§ ÙØ´Ù„ Ø§Ù„Ø¬Ù„Ø¨
    
    avg_price = sum(prices) / len(prices)
    min_price = min(prices)
    max_price = max(prices)

    return {
        "Ù…ØªÙˆØ³Ø·_Ø§Ù„Ø³Ø¹Ø±": round(avg_price, 2),
        "Ù†Ø·Ø§Ù‚_Ø§Ù„Ø³Ø¹Ø±": [min_price, max_price],
        "Ø¹Ø¯Ø¯_Ø§Ù„Ù†ØªØ§Ø¦Ø¬": len(prices),
    }
